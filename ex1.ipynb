{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from sympy import false\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ],
   "id": "2b44c8931b563eb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = nn.Sequential(\n",
    "\n",
    "    # Block 1\n",
    "    nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),      # 32×32 → 16×16\n",
    "\n",
    "    # Block 2\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),      # 16×16 → 8×8\n",
    "\n",
    "    # Block 3\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),      # 8×8 → 4×4\n",
    "\n",
    "    # Block 4\n",
    "    nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(256 * 4 * 4, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 100)   # CIFAR-100\n",
    ")\n"
   ],
   "id": "d3de6518b38177fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def make_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),      # 32×32 → 16×16\n",
    "\n",
    "        # Block 2\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),      # 16×16 → 8×8\n",
    "\n",
    "        # Block 3\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),      # 8×8 → 4×4\n",
    "\n",
    "        # Block 4\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Flatten(),\n",
    "\n",
    "        nn.Linear(256 * 4 * 4, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, 100)   # CIFAR-100\n",
    "    )\n"
   ],
   "id": "c2f5d524ab70eea1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def set_seed(seed):\n",
    "    import random, numpy as np, torch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ],
   "id": "b61ea9d42ca8693d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_training_curves(results_dict):\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    # ---- Training Loss ----\n",
    "    plt.subplot(2,2,1)\n",
    "    for name, history in results_dict.items():\n",
    "        plt.plot(history[\"train_loss\"], label=f\"{name} Train Loss\")\n",
    "    plt.title(\"Training Loss Comparison\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    for name, history in results_dict.items():\n",
    "        plt.plot(history[\"train_acc\"], label=f\"{name} Train Accuracy\")\n",
    "    plt.title(\"Training Accuracy Comparison\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    # ---- Validation Accuracy ----\n",
    "    plt.subplot(2,2,3)\n",
    "    for name, history in results_dict.items():\n",
    "        plt.plot(history[\"val_loss\"], label=f\"{name} Val Loss\")\n",
    "    plt.title(\"Validation Loss Comparison\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    for name, history in results_dict.items():\n",
    "        plt.plot(history[\"val_acc\"], label=f\"{name} Val Acc\")\n",
    "    plt.title(\"Validation Accuracy Comparison\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "fd3a804f59f371e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3. CIFAR-100 DATASET\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "id": "be2cd17589f477cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4. Ορισμός συναρτήσεων κόστους και βελτιστοποίησης\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ],
   "id": "67d3c8dff2bacf9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --------------------------------------------------------\n",
    "# 5. Training\n",
    "# --------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = make_model().to(device)\n",
    "\n",
    "def train_one(model, train_loader, test_loader, criterion, optimizer, device, epochs):\n",
    "    model.to(device)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\",leave=False)\n",
    "\n",
    "        for images, labels in train_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            train_bar.set_postfix(\n",
    "                loss=loss.item(),\n",
    "                accuracy=100 * correct / total\n",
    "            )\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100*correct/total\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion, device, epoch, epochs)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} \"\n",
    "          f\"| TrainLoss: {train_loss:.4f} \"\n",
    "          f\"| ValLoss: {val_loss:.4f} \"\n",
    "          f\"| TrainAcc: {train_acc:.2f}% \"\n",
    "          f\"| ValAcc: {val_acc:.2f}%\")\n",
    "\n",
    "    return history\n",
    "\n"
   ],
   "id": "a90834084fa0fb74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(model, loader, criterion, device, epoch=None, epochs=None):\n",
    "    model.eval()\n",
    "    correct, total = 0,0\n",
    "    running_loss = 0\n",
    "\n",
    "    desc = \"Validation\" if epoch is None else f\"Epoch {epoch+1}/{epochs} [Val]\"\n",
    "    val_bar = tqdm(loader, desc=desc, leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            correct += (preds==labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            val_bar.set_postfix(\n",
    "                loss=loss.item(),\n",
    "                accuracy=100 * correct / total\n",
    "            )\n",
    "\n",
    "    val_loss = running_loss / len(loader)\n",
    "    val_acc = 100*correct/total\n",
    "    return val_loss, val_acc"
   ],
   "id": "dfeade00a7572b0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def show_predictions(model, loader, device, class_names, n=8):\n",
    "    model.eval()\n",
    "\n",
    "    images, labels = next(iter(loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    images = images.cpu()\n",
    "    labels = labels.cpu()\n",
    "    preds = preds.cpu()\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.subplot(2, n//2, i+1)\n",
    "\n",
    "        # unnormalize\n",
    "        img = images[i].permute(1,2,0)\n",
    "        img = img * torch.tensor([0.2675, 0.2565, 0.2761]) + torch.tensor([0.5071, 0.4867, 0.4408])\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        plt.imshow(img)\n",
    "        true_label = class_names[labels[i]]\n",
    "        pred_label = class_names[preds[i]]\n",
    "\n",
    "        color = \"green\" if labels[i] == preds[i] else \"red\"\n",
    "\n",
    "        plt.title(f\"T: {true_label}\\nP: {pred_label}\", color=color, fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Classification results (Green=Correct, Red=Wrong)\", fontsize=14)\n",
    "    plt.show()\n"
   ],
   "id": "da02999fabeab6ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lrs = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "results = {}\n",
    "for lr in lrs:\n",
    "    print(f\"Training with LR={lr}\")\n",
    "    set_seed(0)\n",
    "    model = make_model()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = train_one(model, train_loader, test_loader, criterion, optimizer, device, epochs=5)\n",
    "\n",
    "    results[lr] = history\n",
    "\n",
    "plot_training_curves(results)"
   ],
   "id": "4092bc6021a6969b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.optim import  Adam, SGD, RMSprop\n",
    "\n",
    "results = {}\n",
    "optimizers = [Adam, SGD, RMSprop]\n",
    "for opt_cls in optimizers:\n",
    "    name = opt_cls.__name__\n",
    "    print(f\"Training with {name}\")\n",
    "    set_seed(0)\n",
    "    model = make_model().to(device)\n",
    "    optimizer = opt_cls(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = train_one(model, train_loader, test_loader, criterion, optimizer, device, epochs=5)\n",
    "\n",
    "    results[name] = history\n",
    "\n",
    "plot_training_curves(results)"
   ],
   "id": "dab38a2658665c11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "losses = {\n",
    "    \"CrossEntropy\": nn.CrossEntropyLoss(),\n",
    "    \"LabelSmoothing0.1\":nn .CrossEntropyLoss(label_smoothing=0.1)\n",
    "}\n",
    "results = {}\n",
    "for name, loss_fn in losses.items():\n",
    "    print(f\"Training with {name}\")\n",
    "    set_seed(0)\n",
    "    model = make_model().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    history = train_one(model, train_loader, test_loader, loss_fn, optimizer, device, epochs=10)\n",
    "    results[name] = history\n",
    "\n",
    "\n",
    "plot_training_curves(results)\n"
   ],
   "id": "7fcc136b99b7372d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ενδεικτικά Αποτελέσματα Ταξινόμησης\n",
    "class_names = test_dataset.classes\n",
    "show_predictions(model, test_loader, device, class_names, n=8)\n"
   ],
   "id": "15ad479a76c963ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
